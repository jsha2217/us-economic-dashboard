"""
Google Gemini AI ì„œë¹„ìŠ¤
ê²½ì œ ì§€í‘œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.
"""
import google.generativeai as genai
from typing import Dict, List, Optional
from app.config import get_settings

settings = get_settings()


class GeminiService:
    """
    Google Gemini AI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    """

    def __init__(self):
        # Gemini API ì„¤ì •
        genai.configure(api_key=settings.gemini_api_key)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™•ì¸
        try:
            available_models = [m.name for m in genai.list_models()
                                if 'generateContent' in m.supported_generation_methods]
            print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ (generateContent ì§€ì›): {available_models[:5]}")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            available_models = []

        # ìµœì‹  ëª¨ë¸ ìš°ì„  ìˆœìœ„ë¡œ ì‹œë„
        model_options = [
            'models/gemini-2.5-flash',  # ìµœì‹  (ë¡œê·¸ì—ì„œ í™•ì¸ë¨)
            'models/gemini-2.0-flash-exp',  # ì‹¤í—˜ ë²„ì „
            'models/gemini-2.0-flash',  # 2.0 ë²„ì „
            'models/gemini-1.5-flash',  # 1.5 ë²„ì „
            'models/gemini-1.5-pro',
            'models/gemini-pro',
            'gemini-2.5-flash',  # models/ ì—†ëŠ” ë²„ì „ë„ ì‹œë„
            'gemini-2.0-flash',
            'gemini-1.5-flash',
            'gemini-pro'
        ]

        self.model = None
        for model_name in model_options:
            try:
                print(f"ğŸ” ëª¨ë¸ ì‹œë„ ì¤‘: {model_name}")
                self.model = genai.GenerativeModel(model_name)
                # ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ”ì§€ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
                test_response = self.model.generate_content("í…ŒìŠ¤íŠ¸")
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ ì„±ê³µ: {model_name}")
                break
            except Exception as e:
                print(f"âŒ {model_name} ì‹¤íŒ¨: {str(e)[:100]}")
                continue

        if self.model is None:
            raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def _prepare_economic_context(self, indicators: Dict) -> str:
        """
        ê²½ì œ ì§€í‘œ ë°ì´í„°ë¥¼ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
        """
        context = "í˜„ì¬ ë¯¸êµ­ ê²½ì œ ì§€í‘œ:\n\n"

        # ê¸ˆë¦¬
        if 'interest_rates' in indicators:
            context += "ã€ê¸ˆë¦¬ã€‘\n"
            for key, data in indicators['interest_rates'].items():
                context += f"- {data['name']}: {data['value']}% ({data['date']})\n"
            context += "\n"

        # ë¬¼ê°€
        if 'inflation' in indicators:
            context += "ã€ë¬¼ê°€ã€‘\n"
            for key, data in indicators['inflation'].items():
                context += f"- {data['name']}: {data['value']} ({data['date']})\n"
            context += "\n"

        # ê³ ìš©
        if 'employment' in indicators:
            context += "ã€ê³ ìš©ã€‘\n"
            for key, data in indicators['employment'].items():
                value_str = f"{data['value']}%" if key == 'UNRATE' else f"{data['value']:,}"
                context += f"- {data['name']}: {value_str} ({data['date']})\n"
            context += "\n"

        # GDP
        if 'gdp' in indicators:
            context += "ã€GDP ë° ì„±ì¥ã€‘\n"
            for key, data in indicators['gdp'].items():
                value_str = f"{data['value']}%" if 'Growth' in data['name'] else f"{data['value']:,}"
                context += f"- {data['name']}: {value_str} ({data['date']})\n"
            context += "\n"

        # ê²½ê¸°ì„ í–‰ì§€ìˆ˜
        if 'leading' in indicators:
            context += "ã€ê²½ê¸°ì„ í–‰ì§€ìˆ˜ã€‘\n"
            for key, data in indicators['leading'].items():
                context += f"- {data['name']}: {data['value']} ({data['date']})\n"
            context += "\n"

        return context

    async def analyze_economy(self, indicators: Dict) -> Dict:
        """
        ê²½ì œ ìƒí™©ì„ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤.
        """
        try:
            # ê²½ì œ ë°ì´í„° ì¤€ë¹„
            context = self._prepare_economic_context(indicators)

            # ğŸ‘‡ 2ê°œ ì„¹ì…˜ë§Œ ìš”ì²­
            prompt = f"""ë‹¹ì‹ ì€ ê²½ì œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¯¸êµ­ ê²½ì œ ì§€í‘œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

    {context}

    ë‹¤ìŒ 2ê°€ì§€ë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”:

    ## ì „ì²´ ìš”ì•½
    (í˜„ì¬ ë¯¸êµ­ ê²½ì œ ìƒí™©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)

    ## ë¯¸êµ­ ì¦ì‹œ íˆ¬ì ì „ë§
    (S&P500, ë‚˜ìŠ¤ë‹¥ ë“± ë¯¸êµ­ ì¦ì‹œ íˆ¬ì ì „ë§ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì œì‹œ)

    í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

            # Gemini API í˜¸ì¶œ
            print("ğŸ¤– Gemini API í˜¸ì¶œ ì¤‘...")
            response = self.model.generate_content(prompt)

            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.text
            print(f"âœ… AI ë¶„ì„ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(analysis_text)})")

            # ğŸ‘‡ 2ê°œ ì„¹ì…˜ íŒŒì‹±
            lines = analysis_text.strip().split('\n')

            summary = ""
            outlook = ""
            current_section = None

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # ì„¹ì…˜ í—¤ë” ê°ì§€
                if 'ì „ì²´ ìš”ì•½' in line or line.startswith('## ì „ì²´ ìš”ì•½'):
                    current_section = 'summary'
                    continue
                elif 'ë¯¸êµ­ ì¦ì‹œ' in line or 'íˆ¬ì ì „ë§' in line or line.startswith('## ë¯¸êµ­'):
                    current_section = 'outlook'
                    continue

                # ë‚´ìš© ì €ì¥ (**, # ì œê±°)
                clean_line = line.replace('**', '').replace('#', '').strip()

                if not clean_line:
                    continue

                if current_section == 'summary':
                    summary += clean_line + " "
                elif current_section == 'outlook':
                    outlook += clean_line + " "

            # ê²°ê³¼ ì •ë¦¬
            summary = summary.strip()
            outlook = outlook.strip()

            # Fallback
            if not summary:
                summary = "ë¯¸êµ­ ê²½ì œëŠ” í˜„ì¬ ì•ˆì •ì ì¸ ìƒí™©ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤."

            if not outlook:
                outlook = "ì‹œì¥ ìƒí™©ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."

            print(f"ğŸ“Š íŒŒì‹± ê²°ê³¼:")
            print(f"   ì „ì²´ ìš”ì•½: {len(summary)} ê¸€ì")
            print(f"   íˆ¬ì ì „ë§: {len(outlook)} ê¸€ì")

            return {
                "summary": summary,
                "outlook": outlook,
                "raw_analysis": analysis_text
            }

        except Exception as e:
            print(f"âŒ Gemini API ì—ëŸ¬: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "summary": "AI ë¶„ì„ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "outlook": "ë°ì´í„°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "error": str(e)
            }

    async def generate_quick_insight(self, indicator_name: str, current_value: float,
                                     previous_value: Optional[float] = None) -> str:
        """
        íŠ¹ì • ì§€í‘œì— ëŒ€í•œ ê°„ë‹¨í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        """
        try:
            change_text = ""
            if previous_value is not None:
                change = current_value - previous_value
                change_text = f"ì´ì „ {previous_value}ì—ì„œ {change:+.2f} ë³€í™”í–ˆìŠµë‹ˆë‹¤."

            prompt = f"""{indicator_name}ê°€ í˜„ì¬ {current_value}ì…ë‹ˆë‹¤. {change_text}
ì´ê²ƒì´ ê²½ì œì— ì–´ë–¤ ì˜ë¯¸ì¸ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

            response = self.model.generate_content(prompt)
            return response.text.strip()

        except Exception as e:
            print(f"âŒ Gemini API ì—ëŸ¬: {str(e)}")
            return f"{indicator_name}: {current_value}"


def get_gemini_service() -> GeminiService:
    """
    GeminiService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return GeminiService()