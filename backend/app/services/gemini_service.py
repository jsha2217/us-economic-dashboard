"""
Google Gemini AI ì„œë¹„ìŠ¤
ê²½ì œ ì§€í‘œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.
"""
import google.generativeai as genai
from typing import Dict, List, Optional
from app.config import get_settings

settings = get_settings()


class GeminiService:
    """
    Google Gemini AI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    """

    def __init__(self):
        # Gemini API ì„¤ì •
        genai.configure(api_key=settings.gemini_api_key)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™•ì¸
        try:
            available_models = [m.name for m in genai.list_models()
                                if 'generateContent' in m.supported_generation_methods]
            print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ (generateContent ì§€ì›): {available_models[:5]}")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            available_models = []

        # ìµœì‹  ëª¨ë¸ ìš°ì„  ìˆœìœ„ë¡œ ì‹œë„
        model_options = [
            'models/gemini-2.5-flash',  # ìµœì‹  (ë¡œê·¸ì—ì„œ í™•ì¸ë¨)
            'models/gemini-2.0-flash-exp',  # ì‹¤í—˜ ë²„ì „
            'models/gemini-2.0-flash',  # 2.0 ë²„ì „
            'models/gemini-1.5-flash',  # 1.5 ë²„ì „
            'models/gemini-1.5-pro',
            'models/gemini-pro',
            'gemini-2.5-flash',  # models/ ì—†ëŠ” ë²„ì „ë„ ì‹œë„
            'gemini-2.0-flash',
            'gemini-1.5-flash',
            'gemini-pro'
        ]

        self.model = None
        for model_name in model_options:
            try:
                print(f"ğŸ” ëª¨ë¸ ì‹œë„ ì¤‘: {model_name}")
                self.model = genai.GenerativeModel(model_name)
                # ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ”ì§€ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
                test_response = self.model.generate_content("í…ŒìŠ¤íŠ¸")
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ ì„±ê³µ: {model_name}")
                break
            except Exception as e:
                print(f"âŒ {model_name} ì‹¤íŒ¨: {str(e)[:100]}")
                continue

        if self.model is None:
            raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def _prepare_economic_context(self, indicators: Dict) -> str:
        """
        ê²½ì œ ì§€í‘œ ë°ì´í„°ë¥¼ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
        """
        context = "í˜„ì¬ ë¯¸êµ­ ê²½ì œ ì§€í‘œ:\n\n"

        # ê¸ˆë¦¬
        if 'interest_rates' in indicators:
            context += "ã€ê¸ˆë¦¬ã€‘\n"
            for key, data in indicators['interest_rates'].items():
                context += f"- {data['name']}: {data['value']}% ({data['date']})\n"
            context += "\n"

        # ë¬¼ê°€
        if 'inflation' in indicators:
            context += "ã€ë¬¼ê°€ã€‘\n"
            for key, data in indicators['inflation'].items():
                context += f"- {data['name']}: {data['value']} ({data['date']})\n"
            context += "\n"

        # ê³ ìš©
        if 'employment' in indicators:
            context += "ã€ê³ ìš©ã€‘\n"
            for key, data in indicators['employment'].items():
                value_str = f"{data['value']}%" if key == 'UNRATE' else f"{data['value']:,}"
                context += f"- {data['name']}: {value_str} ({data['date']})\n"
            context += "\n"

        # GDP
        if 'gdp' in indicators:
            context += "ã€GDP ë° ì„±ì¥ã€‘\n"
            for key, data in indicators['gdp'].items():
                value_str = f"{data['value']}%" if 'Growth' in data['name'] else f"{data['value']:,}"
                context += f"- {data['name']}: {value_str} ({data['date']})\n"
            context += "\n"

        # ê²½ê¸°ì„ í–‰ì§€ìˆ˜
        if 'leading' in indicators:
            context += "ã€ê²½ê¸°ì„ í–‰ì§€ìˆ˜ã€‘\n"
            for key, data in indicators['leading'].items():
                context += f"- {data['name']}: {data['value']} ({data['date']})\n"
            context += "\n"

        return context

    async def analyze_economy(self, indicators: Dict) -> Dict:
        """
        ê²½ì œ ìƒí™©ì„ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤.
        """
        try:
            # ê²½ì œ ë°ì´í„° ì¤€ë¹„
            context = self._prepare_economic_context(indicators)

            # AI í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""ë‹¹ì‹ ì€ ê²½ì œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¯¸êµ­ ê²½ì œ ì§€í‘œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

{context}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë¶„ì„í•´ì£¼ì„¸ìš”:

## ì „ì²´ ìš”ì•½
(2-3ë¬¸ì¥ìœ¼ë¡œ ì „ì²´ ê²½ì œ ìƒí™© ìš”ì•½)

## ì£¼ìš” í¬ì¸íŠ¸
- (í¬ì¸íŠ¸ 1)
- (í¬ì¸íŠ¸ 2)

## í–¥í›„ ì „ë§
(2-3ë¬¸ì¥ìœ¼ë¡œ í–¥í›„ ì „ë§ ì˜ˆì¸¡ê³¼ íˆ¬ì ì¡°ì–¸)

í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

            # Gemini API í˜¸ì¶œ
            print("ğŸ¤– Gemini API í˜¸ì¶œ ì¤‘...")
            response = self.model.generate_content(prompt)

            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.text
            print(f"âœ… AI ë¶„ì„ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(analysis_text)})")
            print(f"ğŸ“„ ì›ë³¸ ë¶„ì„:\n{analysis_text}\n")

            # ê°„ë‹¨í•œ íŒŒì‹±
            lines = analysis_text.strip().split('\n')

            summary = ""
            key_points = []
            outlook = ""

            current_section = None

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                if 'ì „ì²´ ìš”ì•½' in line or 'ìš”ì•½' in line or '1.' in line:
                    current_section = 'summary'
                    continue
                elif 'ì£¼ìš” í¬ì¸íŠ¸' in line or 'í¬ì¸íŠ¸' in line or '2.' in line:
                    current_section = 'points'
                    continue
                elif 'ì „ë§' in line or 'outlook' in line.lower() or '3.' in line:
                    current_section = 'outlook'
                    continue

                # ë²ˆí˜¸ë‚˜ ë¶ˆë¦¿ ì œê±°
                clean_line = line.lstrip('0123456789.-â€¢*# ')

                if current_section == 'summary' and clean_line:
                    summary += clean_line + " "
                elif current_section == 'points' and clean_line:
                    key_points.append(clean_line)
                elif current_section == 'outlook' and clean_line:
                    outlook += clean_line + " "

            return {
                "summary": summary.strip() or analysis_text[:300],
                "key_points": key_points if key_points else ["ë¶„ì„ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."],
                "outlook": outlook.strip() or "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "raw_analysis": analysis_text
            }

        except Exception as e:
            print(f"âŒ Gemini API ì—ëŸ¬: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "summary": "AI ë¶„ì„ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "key_points": ["í˜„ì¬ ê²½ì œ ì§€í‘œë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤."],
                "outlook": "ë°ì´í„°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "error": str(e)
            }

    async def generate_quick_insight(self, indicator_name: str, current_value: float,
                                     previous_value: Optional[float] = None) -> str:
        """
        íŠ¹ì • ì§€í‘œì— ëŒ€í•œ ê°„ë‹¨í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        """
        try:
            change_text = ""
            if previous_value is not None:
                change = current_value - previous_value
                change_text = f"ì´ì „ {previous_value}ì—ì„œ {change:+.2f} ë³€í™”í–ˆìŠµë‹ˆë‹¤."

            prompt = f"""{indicator_name}ê°€ í˜„ì¬ {current_value}ì…ë‹ˆë‹¤. {change_text}
ì´ê²ƒì´ ê²½ì œì— ì–´ë–¤ ì˜ë¯¸ì¸ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

            response = self.model.generate_content(prompt)
            return response.text.strip()

        except Exception as e:
            print(f"âŒ Gemini API ì—ëŸ¬: {str(e)}")
            return f"{indicator_name}: {current_value}"


def get_gemini_service() -> GeminiService:
    """
    GeminiService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return GeminiService()